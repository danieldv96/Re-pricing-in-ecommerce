{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b6e4a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from cdt.metrics import SHD\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
    "\n",
    "def extract_vars_and_lag(filename):\n",
    "    vars_match = re.search(r'vars(\\d+)', filename)\n",
    "    lag_match = re.search(r'lag(\\d+)', filename)\n",
    "\n",
    "    if vars_match and lag_match:\n",
    "        return int(vars_match.group(1)), int(lag_match.group(1))\n",
    "\n",
    "    return None, None\n",
    "\n",
    "def get_truth_matrices(n_vars, lag):\n",
    "    # All truth matrices from the timegraph study are included here, see readme for reference \n",
    "\n",
    "    if n_vars == 4:\n",
    "        if lag == 2:\n",
    "            truth_matrix = np.array([\n",
    "                [0, 0, 0, 1], \n",
    "                [1, 0, 0, 0], \n",
    "                [0, 1, 0, 0],  \n",
    "                [0, 0, 1, 0]   \n",
    "            ])\n",
    "            truth_lag_matrix = np.array([\n",
    "                [0, 0, 0, 2],  \n",
    "                [0, 0, 0, 0],  \n",
    "                [0, 1, 0, 0],  \n",
    "                [0, 0, 0, 0]  \n",
    "            ])\n",
    "        elif lag == 3:\n",
    "            truth_matrix = np.array([\n",
    "                [0, 0, 0, 1], \n",
    "                [1, 0, 1, 0], \n",
    "                [0, 1, 0, 0],  \n",
    "                [0, 0, 1, 0]   \n",
    "            ])\n",
    "            truth_lag_matrix = np.array([\n",
    "                [0, 0, 0, 2],  \n",
    "                [0, 0, 3, 0],  \n",
    "                [0, 1, 0, 0],  \n",
    "                [0, 0, 0, 0]  \n",
    "            ])\n",
    "        elif lag == 4:\n",
    "            truth_matrix = np.array([\n",
    "                [0, 0, 0, 1],  \n",
    "                [1, 0, 1, 0],  \n",
    "                [0, 1, 0, 0],  \n",
    "                [0, 0, 1, 0]   \n",
    "            ])\n",
    "            truth_lag_matrix = np.array([\n",
    "                [0, 0, 0, 4],  \n",
    "                [0, 0, 3, 0],  \n",
    "                [0, 1, 0, 0],  \n",
    "                [0, 0, 0, 0]  \n",
    "            ])\n",
    "\n",
    "    elif n_vars == 6:\n",
    "        if lag == 2:\n",
    "            truth_matrix = np.array([\n",
    "                [0, 0, 0, 1, 0, 0], \n",
    "                [1, 0, 0, 0, 0, 0], \n",
    "                [0, 1, 0, 0, 0, 0],  \n",
    "                [0, 0, 1, 0, 0, 0], \n",
    "                [0, 0, 0, 1, 0, 0],  \n",
    "                [0, 0, 0, 0, 1, 0]   \n",
    "            ])\n",
    "            truth_matrix[4, 3] = 1 \n",
    "\n",
    "            truth_lag_matrix = np.array([\n",
    "                [0, 0, 0, 2, 0, 0],  \n",
    "                [0, 0, 0, 0, 0, 0],  \n",
    "                [0, 1, 0, 0, 0, 0],  \n",
    "                [0, 0, 0, 0, 0, 0],  \n",
    "                [0, 0, 0, 1, 0, 0],  \n",
    "                [0, 0, 0, 0, 0, 0]   \n",
    "            ])\n",
    "            truth_lag_matrix[4, 3] = 1  \n",
    "\n",
    "        elif lag == 3:\n",
    "            truth_matrix = np.array([\n",
    "                [0, 0, 0, 1, 0, 0],  \n",
    "                [1, 0, 1, 0, 0, 0],  \n",
    "                [0, 1, 0, 0, 0, 0],  \n",
    "                [0, 0, 1, 0, 0, 0], \n",
    "                [0, 0, 0, 1, 0, 0],  \n",
    "                [0, 0, 0, 0, 1, 0]   \n",
    "            ])\n",
    "\n",
    "            truth_lag_matrix = np.array([\n",
    "                [0, 0, 0, 2, 0, 0],  \n",
    "                [0, 0, 3, 0, 0, 0], \n",
    "                [0, 1, 0, 0, 0, 0],  \n",
    "                [0, 0, 0, 0, 0, 0], \n",
    "                [0, 0, 0, 1, 0, 0],  \n",
    "                [0, 0, 0, 0, 0, 0]   \n",
    "            ])\n",
    "\n",
    "        elif lag == 4:\n",
    "            truth_matrix = np.array([\n",
    "                [0, 0, 0, 1, 0, 0],  \n",
    "                [1, 0, 1, 0, 0, 0], \n",
    "                [0, 1, 0, 0, 0, 0],  \n",
    "                [0, 0, 1, 0, 0, 0], \n",
    "                [0, 0, 0, 1, 0, 0],  \n",
    "                [0, 0, 0, 0, 1, 0]   \n",
    "            ])\n",
    "\n",
    "            truth_lag_matrix = np.array([\n",
    "                [0, 0, 0, 4, 0, 0], \n",
    "                [0, 0, 3, 0, 0, 0],  \n",
    "                [0, 1, 0, 0, 0, 0], \n",
    "                [0, 0, 0, 0, 0, 0], \n",
    "                [0, 0, 0, 1, 0, 0], \n",
    "                [0, 0, 0, 0, 0, 0]  \n",
    "            ])\n",
    "\n",
    "    # 8 variables\n",
    "    elif n_vars == 8:\n",
    "        if lag == 2:\n",
    "            truth_matrix = np.zeros((8, 8))\n",
    "\n",
    "            truth_matrix[0, 3] = 1  \n",
    "            truth_matrix[3, 2] = 1  \n",
    "            truth_matrix[2, 1] = 1  \n",
    "            truth_matrix[1, 0] = 1  \n",
    "\n",
    "            truth_matrix[3, 4] = 1  \n",
    "            truth_matrix[4, 5] = 1  \n",
    "            truth_matrix[5, 6] = 1 \n",
    "            truth_matrix[6, 7] = 1  \n",
    "\n",
    "            truth_matrix[4, 3] = 1  \n",
    "\n",
    "            truth_lag_matrix = np.zeros((8, 8), dtype=int)\n",
    "            truth_lag_matrix[0, 3] = 2  \n",
    "            truth_lag_matrix[2, 1] = 1  \n",
    "            truth_lag_matrix[3, 4] = 1  \n",
    "            truth_lag_matrix[5, 6] = 1  \n",
    "            truth_lag_matrix[4, 3] = 1  \n",
    "\n",
    "        elif lag == 3:\n",
    "            truth_matrix = np.zeros((8, 8))\n",
    "            truth_matrix[0, 3] = 1  \n",
    "            truth_matrix[3, 2] = 1  \n",
    "            truth_matrix[2, 1] = 1  \n",
    "            truth_matrix[1, 0] = 1 \n",
    "            truth_matrix[1, 2] = 1  \n",
    "            truth_matrix[3, 4] = 1  \n",
    "            truth_matrix[4, 5] = 1 \n",
    "            truth_matrix[5, 6] = 1  \n",
    "            truth_matrix[6, 7] = 1  \n",
    "\n",
    "            truth_lag_matrix = np.zeros((8, 8), dtype=int)\n",
    "            truth_lag_matrix[0, 3] = 2 \n",
    "            truth_lag_matrix[2, 1] = 1 \n",
    "            truth_lag_matrix[1, 2] = 3  \n",
    "            truth_lag_matrix[3, 4] = 1 \n",
    "            truth_lag_matrix[5, 6] = 1 \n",
    "\n",
    "        elif lag == 4:\n",
    "            truth_matrix = np.zeros((8, 8))\n",
    "            truth_matrix[0, 3] = 1  \n",
    "            truth_matrix[3, 2] = 1  \n",
    "            truth_matrix[2, 1] = 1  \n",
    "            truth_matrix[1, 0] = 1  \n",
    "            truth_matrix[1, 2] = 1  \n",
    "            truth_matrix[3, 4] = 1  \n",
    "            truth_matrix[4, 5] = 1 \n",
    "            truth_matrix[5, 6] = 1 \n",
    "            truth_matrix[6, 7] = 1  \n",
    "\n",
    "            truth_lag_matrix = np.zeros((8, 8), dtype=int)\n",
    "            truth_lag_matrix[0, 3] = 4  \n",
    "            truth_lag_matrix[2, 1] = 1  \n",
    "            truth_lag_matrix[1, 2] = 3  \n",
    "            truth_lag_matrix[3, 4] = 1  \n",
    "            truth_lag_matrix[5, 6] = 1  \n",
    "\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "    return truth_matrix, truth_lag_matrix\n",
    "\n",
    "def determine_data_type(file):\n",
    "    if 'nonlinear' in file.lower() or 'C1' in file:\n",
    "        return 'nonlinear'\n",
    "    else:\n",
    "        return 'linear'\n",
    "\n",
    "def calculate_metrics(pred_matrix, pred_lag_matrix, truth_matrix, truth_lag_matrix):\n",
    "    truth_binary = truth_matrix.astype(int)\n",
    "\n",
    "    N = truth_binary.shape[0]\n",
    "    select_off_diagonal = (np.identity(N) == 0)\n",
    "    y_true = truth_binary[select_off_diagonal]\n",
    "    y_scores = pred_matrix[select_off_diagonal]\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "\n",
    "    metrics['auc'] = roc_auc_score(y_true, y_scores)\n",
    "    \n",
    "    metrics['shd'] = SHD(truth_binary, pred_matrix)\n",
    "\n",
    "    # Confusion matrix values calculations \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    metrics['tpr'] = tpr[optimal_idx]\n",
    "    metrics['fpr'] = fpr[optimal_idx]\n",
    "\n",
    "    y_pred_binary = (y_scores >= optimal_threshold).astype(int)\n",
    "\n",
    "\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
    "    except Exception as e:\n",
    "        tn, fp, fn, tp = 0, 0, 0, 0\n",
    "\n",
    "    # False Discovery Rate as specify in the paper\n",
    "    metrics['fdr'] = fp / (fp + tp) if (fp + tp) > 0 else 0.0\n",
    "\n",
    "    lag_errors = []\n",
    "    detected_edges = (pred_matrix > 0) & (truth_binary > 0)\n",
    "\n",
    "    true_lag_binary = (truth_lag_matrix > 0).astype(int)\n",
    "    pred_lag_binary = (pred_lag_matrix > 0).astype(int)\n",
    "\n",
    "    masked_true_lag = true_lag_binary * detected_edges\n",
    "    masked_pred_lag = pred_lag_binary * detected_edges\n",
    "\n",
    "    if np.sum(detected_edges) > 0:\n",
    "        lag_true_flat = masked_true_lag[select_off_diagonal]\n",
    "        lag_pred_flat = masked_pred_lag[select_off_diagonal]\n",
    "        lag_scores_flat = pred_lag_matrix[select_off_diagonal] * detected_edges[select_off_diagonal]\n",
    "\n",
    "        if len(np.unique(lag_true_flat)) > 1:\n",
    "            metrics['lag_auc'] = roc_auc_score(lag_true_flat, lag_scores_flat)\n",
    "            lag_fpr, lag_tpr, _ = roc_curve(lag_true_flat, lag_scores_flat)\n",
    "            lag_optimal_idx = np.argmax(lag_tpr - lag_fpr)\n",
    "            metrics['lag_tpr'] = lag_tpr[lag_optimal_idx]\n",
    "            metrics['lag_fpr'] = lag_fpr[lag_optimal_idx]\n",
    "        else:\n",
    "            metrics['lag_auc'] = 0.5\n",
    "            metrics['lag_tpr'] = 0.0\n",
    "            metrics['lag_fpr'] = 0.0\n",
    "\n",
    "        metrics['lag_shd'] = np.sum(masked_true_lag != masked_pred_lag)\n",
    "    else:\n",
    "        metrics['lag_auc'] = 0\n",
    "        metrics['lag_tpr'] = 0\n",
    "        metrics['lag_fpr'] = 0\n",
    "        metrics['lag_shd'] = 0\n",
    "\n",
    "\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def find_all_datasets(base_path='/content/TimeGraph/Datasets', sample_size=500):\n",
    "    datasets = []\n",
    "    for filepath in glob.glob(os.path.join(base_path, '**/*.csv'), recursive=True):\n",
    "        filename = os.path.basename(filepath)\n",
    "        # missing samples were not taken into account for this research and this function creation\n",
    "        #remove D here to include all samples\n",
    "        if (f'n{sample_size}' in filename and f'n{sample_size}0' not in filename and\n",
    "            ('D1' not in filepath and 'D2' not in filepath and 'D3' not in filepath)):\n",
    "            datasets.append(filepath)\n",
    "\n",
    "    return sorted(datasets)\n",
    "\n",
    "def extract_test_name(filepath):\n",
    "    parts = filepath.split('/')\n",
    "\n",
    "    dataset_type = None\n",
    "    detail_parts = []\n",
    "\n",
    "    for i, part in enumerate(parts):\n",
    "        if part in ['A1','A1C', 'A2','A2C', 'B1', 'B1C', 'B2', 'B2C',\n",
    "                    'C1', 'C1C', 'C2', 'C2C']:\n",
    "            dataset_type = part\n",
    "            for j in range(i+1, len(parts)-1):\n",
    "                detail_parts.append(parts[j])\n",
    "            break\n",
    "\n",
    "    filename = parts[-1]\n",
    "    n_vars, lag = extract_vars_and_lag(filename)\n",
    "\n",
    "    sample_match = re.search(r'n(\\d+)', filename)\n",
    "    sample_size = sample_match.group(1) if sample_match else 'unknown'\n",
    "\n",
    "    if dataset_type and detail_parts:\n",
    "        detail_str = ' '.join(detail_parts).replace('_', ' ')\n",
    "        test_name = f\"{dataset_type} with {detail_str} for {sample_size} rows with {n_vars} var and lag {lag}\"\n",
    "    else:\n",
    "        test_name = filename\n",
    "\n",
    "    return test_name\n",
    "\n",
    "def evaluate_causal_models(model_functions):\n",
    "    results = []\n",
    "\n",
    "    print(\"Auto-finding all n500 datasets in /content/TimeGraph/Datasets...\")\n",
    "    datasets = find_all_datasets()\n",
    "    print(f\"Found {len(datasets)} datasets with n500\")\n",
    "    for ds in datasets[:5]:\n",
    "        print(f\"  - {ds}\")\n",
    "    if len(datasets) > 5:\n",
    "        print(f\"  ... and {len(datasets) - 5} more\")\n",
    "\n",
    "    for dataset_path in datasets:\n",
    "        if '/' in dataset_path:\n",
    "            filename = dataset_path.split('/')[-1]\n",
    "        else:\n",
    "            filename = dataset_path\n",
    "\n",
    "        n_vars, lag = extract_vars_and_lag(filename)\n",
    "\n",
    "\n",
    "        truth_matrix, truth_lag_matrix = get_truth_matrices(n_vars, lag)\n",
    "\n",
    "\n",
    "        data_type = determine_data_type(dataset_path)\n",
    "        \n",
    "        for model_name, model_func in model_functions.items():\n",
    "            try:\n",
    "                pred_matrix, pred_lag_matrix = model_func(dataset_path, max_lag=lag)\n",
    "                metrics = calculate_metrics(pred_matrix, pred_lag_matrix, truth_matrix, truth_lag_matrix)\n",
    "\n",
    "                result = {\n",
    "                    'Model': model_name,\n",
    "                    'Dataset': filename,\n",
    "                    'Test_Name': extract_test_name(dataset_path),\n",
    "                    'Type': data_type,\n",
    "                    'Vars': n_vars,\n",
    "                    'Lag': lag,\n",
    "                    'AUC': metrics['auc'],\n",
    "                    'TPR': metrics['tpr'],\n",
    "                    'FPR': metrics['fpr'],\n",
    "                    'SHD': metrics['shd'],\n",
    "                    'Precision': metrics['precision'],\n",
    "                    'FDR': metrics['fdr'],  # Added FDR\n",
    "                    'Specificity': metrics['specificity'],  # Added Specificity\n",
    "                    'Lag_AUC': metrics['lag_auc'],\n",
    "                    'Lag_TPR': metrics['lag_tpr'],\n",
    "                    'Lag_FPR': metrics['lag_fpr'],\n",
    "                    'Lag_SHD': metrics['lag_shd'],\n",
    "                    'Sensitivity': metrics['sensitivity'],\n",
    "                    'Recall': metrics['recall'],\n",
    "                    'F1_Score': metrics['f1_score'],\n",
    "                    'Avg_Lag_Error': metrics['avg_lag_error']\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Model {model_name} failed on {filename}: {str(e)}\")\n",
    "                result = {\n",
    "                    'Model': model_name,\n",
    "                    'Dataset': filename,\n",
    "                    'Test_Name': extract_test_name(dataset_path),\n",
    "                    'Type': data_type,\n",
    "                    'Vars': n_vars,\n",
    "                    'Lag': lag,\n",
    "                    'AUC': np.nan,\n",
    "                    'TPR': np.nan,\n",
    "                    'FPR': np.nan,\n",
    "                    'SHD': np.nan,\n",
    "                    'Precision': np.nan,\n",
    "                    'FDR': np.nan,\n",
    "                    'Specificity': np.nan,\n",
    "                    'Lag_AUC': np.nan,\n",
    "                    'Lag_TPR': np.nan,\n",
    "                    'Lag_FPR': np.nan,\n",
    "                    'Lag_SHD': np.nan,\n",
    "                    'Sensitivity': np.nan,\n",
    "                    'Recall': np.nan,\n",
    "                    'F1_Score': np.nan,\n",
    "                    'Avg_Lag_Error': np.nan\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "model_functions = {\n",
    "    'include_function_here': choose_tested_function\n",
    "}\n",
    "results_df = evaluate_causal_models(model_functions)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
