{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b782a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tslearn.metrics import cdist_dtw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "COLORS = {\n",
    "    'color1': '#1f77b4',\n",
    "    'color2': '#ff7f0e',\n",
    "    'color3': '#2ca02c',\n",
    "    'color4': '#d62728',\n",
    "    'color5': '#9467bd',\n",
    "    'color6': '#8c564b',\n",
    "    'color7': '#e377c2',\n",
    "    'color8': '#7f7f7f',\n",
    "    'color9': '#bcbd22',\n",
    "    'color10': '#17becf',\n",
    "}\n",
    "\n",
    "datasets = ['/content/drive/MyDrive/transformed_data/amazon_buy_box_pricing.csv',\n",
    "            '/content/drive/MyDrive/transformed_data/amazon_pricing.csv',\n",
    "            '/content/drive/MyDrive/transformed_data/lowest_internet_final_df.csv']\n",
    "\n",
    "price_cols = ['buy_box_price', 'amazon_price', 'lowest_internet_price']\n",
    "\n",
    "base_path = \"/content/drive/MyDrive/hierarchical_clustering_results\"\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "for m in range(3):\n",
    "    price_col = price_cols[m]\n",
    "    daily_metrics = {\n",
    "        'amazon_frequency': f'amazon_frequency',\n",
    "        'amazon_realized_variance': f'amazon_realized_variance',\n",
    "        'amazon_intraday_range': f'amazon_intraday_range'\n",
    "    }\n",
    "\n",
    "    # Load and filter data\n",
    "    df = pd.read_csv(datasets[m])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df[(df['date'] >= '2024-09-01') & (df['date'] < '2025-01-01')]\n",
    "\n",
    "    # Create output directory\n",
    "    dataset_path = os.path.join(base_path, f\"amazon_hierarchical\")\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "    metrics_to_use = list(daily_metrics.values())\n",
    "    unique_key = 'query'\n",
    "\n",
    "    # Normalize data per product\n",
    "    normalized_data = []\n",
    "    for product in df[unique_key].unique():\n",
    "        product_data = df[df[unique_key] == product].copy()\n",
    "        if len(product_data) > 1:\n",
    "            scaler = StandardScaler()\n",
    "            for metric in metrics_to_use:\n",
    "                if metric in product_data.columns and product_data[metric].std() > 0:\n",
    "                    product_data[metric] = scaler.fit_transform(product_data[[metric]])\n",
    "\n",
    "        normalized_data.append(product_data)\n",
    "\n",
    "    df_normalized = pd.concat(normalized_data)\n",
    "    df_normalized.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Create time series matrix\n",
    "    products = df_normalized[unique_key].unique()\n",
    "    time_points = sorted(df_normalized['date'].unique())\n",
    "\n",
    "    X = np.zeros((len(products), len(time_points), len(metrics_to_use)))\n",
    "\n",
    "    for k, metric in enumerate(metrics_to_use):\n",
    "        pivot = df_normalized.pivot(index=unique_key, columns='date', values=metric)\n",
    "        pivot = pivot.reindex(index=products, columns=time_points, fill_value=0)\n",
    "        X[:, :, k] = pivot.values\n",
    "\n",
    "    X = np.nan_to_num(X, 0)\n",
    "\n",
    "    print(f\"\\nComputing DTW distance matrix for {len(products)} products...\")\n",
    "\n",
    "    # Compute DTW distance matrix\n",
    "    dtw_dist_matrix = cdist_dtw(X, X, n_jobs=-1)\n",
    "\n",
    "    # Convert to condensed form for scipy\n",
    "    condensed_dist = squareform(dtw_dist_matrix)\n",
    "\n",
    "    # Try different linkage methods\n",
    "    linkage_methods = ['ward']\n",
    "    results = []\n",
    "\n",
    "    for method in linkage_methods:\n",
    "        print(f\"Testing {method} linkage...\")\n",
    "\n",
    "        # Perform hierarchical clustering\n",
    "        if method == 'ward':\n",
    "            # Ward requires squared distances\n",
    "            Z = linkage(condensed_dist**2, method=method)\n",
    "        else:\n",
    "            Z = linkage(condensed_dist, method=method)\n",
    "\n",
    "        # Test different numbers of clusters\n",
    "        silhouette_scores = {}\n",
    "        for n_clusters in range(2, min(10, len(products))):\n",
    "            clusters = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "\n",
    "            # Calculate silhouette score\n",
    "            if len(np.unique(clusters)) > 1:\n",
    "                sil_score = silhouette_score(dtw_dist_matrix, clusters, metric='precomputed')\n",
    "                silhouette_scores[n_clusters] = sil_score\n",
    "\n",
    "        if silhouette_scores:\n",
    "            best_n = max(silhouette_scores, key=silhouette_scores.get)\n",
    "            best_score = silhouette_scores[best_n]\n",
    "\n",
    "            results.append({\n",
    "                'method': method,\n",
    "                'best_n_clusters': best_n,\n",
    "                'silhouette_score': best_score,\n",
    "                'all_scores': silhouette_scores,\n",
    "                'linkage_matrix': Z\n",
    "            })"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
